{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7a00af",
   "metadata": {},
   "source": [
    "# 02 - Preparación de datos y creación de ventanas para LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "643734b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccad6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"../data/raw/continuous_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    ruta,\n",
    "    parse_dates=['datetime'],\n",
    "    index_col='datetime'\n",
    ").sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "868b44e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nat_demand</th>\n",
       "      <th>T2M_toc</th>\n",
       "      <th>T2M_san</th>\n",
       "      <th>T2M_dav</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>holiday</th>\n",
       "      <th>school</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-03 01:00:00</th>\n",
       "      <td>970.3450</td>\n",
       "      <td>25.865259</td>\n",
       "      <td>23.482446</td>\n",
       "      <td>22.662134</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03 02:00:00</th>\n",
       "      <td>912.1755</td>\n",
       "      <td>25.899255</td>\n",
       "      <td>23.399255</td>\n",
       "      <td>22.578943</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03 03:00:00</th>\n",
       "      <td>900.2688</td>\n",
       "      <td>25.937280</td>\n",
       "      <td>23.343530</td>\n",
       "      <td>22.531030</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03 04:00:00</th>\n",
       "      <td>889.9538</td>\n",
       "      <td>25.957544</td>\n",
       "      <td>23.238794</td>\n",
       "      <td>22.512231</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03 05:00:00</th>\n",
       "      <td>893.6865</td>\n",
       "      <td>25.973840</td>\n",
       "      <td>23.075403</td>\n",
       "      <td>22.481653</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     nat_demand    T2M_toc    T2M_san    T2M_dav  hour  \\\n",
       "datetime                                                                 \n",
       "2015-01-03 01:00:00    970.3450  25.865259  23.482446  22.662134     1   \n",
       "2015-01-03 02:00:00    912.1755  25.899255  23.399255  22.578943     2   \n",
       "2015-01-03 03:00:00    900.2688  25.937280  23.343530  22.531030     3   \n",
       "2015-01-03 04:00:00    889.9538  25.957544  23.238794  22.512231     4   \n",
       "2015-01-03 05:00:00    893.6865  25.973840  23.075403  22.481653     5   \n",
       "\n",
       "                     dayofweek  is_weekend  holiday  school  \n",
       "datetime                                                     \n",
       "2015-01-03 01:00:00          5           1        0       0  \n",
       "2015-01-03 02:00:00          5           1        0       0  \n",
       "2015-01-03 03:00:00          5           1        0       0  \n",
       "2015-01-03 04:00:00          5           1        0       0  \n",
       "2015-01-03 05:00:00          5           1        0       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hour'] = df.index.hour\n",
    "df['dayofweek'] = df.index.day_of_week\n",
    "df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
    "\n",
    "feature_cols = [\n",
    "    'nat_demand',\n",
    "    'T2M_toc', 'T2M_san', 'T2M_dav',\n",
    "    'hour', 'dayofweek', 'is_weekend',\n",
    "    'holiday', 'school'\n",
    "]\n",
    "\n",
    "target_col = 'nat_demand'\n",
    "\n",
    "df_model = df[feature_cols].copy()\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b571567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2015-01-03 01:00:00 → 2019-05-23 14:00:00 | filas: 38438\n",
      "Test:  2019-05-23 15:00:00 → 2020-06-27 00:00:00 | filas: 9610\n"
     ]
    }
   ],
   "source": [
    "n = len(df_model)\n",
    "train_size = int(n * 0.8)\n",
    "\n",
    "df_train = df_model.iloc[:train_size]\n",
    "df_test  = df_model.iloc[train_size:]\n",
    "\n",
    "print(\"Train:\", df_train.index.min(), \"→\", df_train.index.max(), \"| filas:\", len(df_train))\n",
    "print(\"Test: \", df_test.index.min(), \"→\", df_test.index.max(),  \"| filas:\", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b425a529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38438, 9) (38438, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train[feature_cols].values\n",
    "y_train = df_train[[target_col]].values   # doble [] -> 2D\n",
    "\n",
    "X_test  = df_test[feature_cols].values\n",
    "y_test  = df_test[[target_col]].values\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)   # fit SOLO en train\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "\n",
    "X_test_scaled  = scaler_X.transform(X_test)        # usamos los mismos params\n",
    "y_test_scaled  = scaler_y.transform(y_test)\n",
    "\n",
    "print(X_train_scaled.shape, y_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44dbdf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, seq_len):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(seq_len, len(X)):\n",
    "        Xs.append(X[i-seq_len:i])  # [t-seq_len, ..., t-1]\n",
    "        ys.append(y[i])            # valor en t\n",
    "    return np.array(Xs), np.array(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d21418a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_seq: (38270, 168, 9)\n",
      "y_train_seq: (38270, 1)\n",
      "X_test_seq : (9442, 168, 9)\n",
      "y_test_seq : (9442, 1)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 24 * 7  # 7 días de historia (168 horas)\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, sequence_length)\n",
    "X_test_seq,  y_test_seq  = create_sequences(X_test_scaled,  y_test_scaled,  sequence_length)\n",
    "\n",
    "print(\"X_train_seq:\", X_train_seq.shape)\n",
    "print(\"y_train_seq:\", y_train_seq.shape)\n",
    "print(\"X_test_seq :\", X_test_seq.shape)\n",
    "print(\"y_test_seq :\", y_test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dc17dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([38270, 168, 9]), torch.Size([38270, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Usando device:\", device)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32).to(device)\n",
    "\n",
    "X_test_tensor  = torch.tensor(X_test_seq,  dtype=torch.float32).to(device)\n",
    "y_test_tensor  = torch.tensor(y_test_seq,  dtype=torch.float32).to(device)\n",
    "\n",
    "X_train_tensor.shape, y_train_tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faea18af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a5f5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "class LSTMForecast(nn.Module): \n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, output_size=1):\n",
    "        super().__init__()\n",
    "        # Capa de LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        # Capa lineal final \n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size)\n",
    "        out, _ = self.lstm(x)\n",
    "\n",
    "        last_hidden = out[:, -1, :]\n",
    "        out = self.fc(last_hidden)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c3da7",
   "metadata": {},
   "source": [
    "Tengo un batch de 64 ventanas.\n",
    "Cada ventana representa 7 días (168 horas) y, en cada hora, tengo 9 features.\n",
    "\n",
    "El LSTM es un solo modelo (no 64 distintos) que procesa las 64 ventanas en paralelo.\n",
    "Si hago zoom en una sola ventana:\n",
    "\n",
    "el LSTM recorre las 168 horas en orden temporal,\n",
    "\n",
    "en cada paso ve un vector de 9 features (esa hora) y actualiza un estado interno (hidden) de tamaño 64,\n",
    "\n",
    "al terminar la hora 168, me quedo con el último hidden, que es un resumen de lo que pasó en esas 168 horas.\n",
    "\n",
    "Ese vector de tamaño 64 lo paso por una capa final (fc) para obtener una predicción de la demanda en la hora siguiente.\n",
    "\n",
    "Esto mismo pasa para las 64 ventanas del batch en paralelo, así que obtengo 64 predicciones.\n",
    "Comparo esas 64 predicciones con los 64 valores reales (y_batch), calculo la pérdida (por ejemplo el MSE promedio) y con eso ajusto los pesos del LSTM y de la capa final para que la próxima vez prediga mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "061cc50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMForecast(\n",
      "  (lstm): LSTM(9, 64, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train_seq.shape[2]\n",
    "\n",
    "model = LSTMForecast(input_size).to(device)\n",
    "\n",
    "model\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adaa6772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.000195, val_loss=0.000337\n",
      "Epoch 2: train_loss=0.000189, val_loss=0.000282\n",
      "Epoch 3: train_loss=0.000187, val_loss=0.000289\n",
      "Epoch 4: train_loss=0.000183, val_loss=0.000281\n",
      "Epoch 5: train_loss=0.000181, val_loss=0.000278\n",
      "Epoch 6: train_loss=0.000183, val_loss=0.000283\n",
      "Epoch 7: train_loss=0.000178, val_loss=0.000322\n",
      "Epoch 8: train_loss=0.000173, val_loss=0.000359\n",
      "Epoch 9: train_loss=0.000180, val_loss=0.000306\n",
      "Epoch 10: train_loss=0.000176, val_loss=0.000311\n",
      "Epoch 11: train_loss=0.000178, val_loss=0.000293\n",
      "Epoch 12: train_loss=0.000173, val_loss=0.000273\n",
      "Epoch 13: train_loss=0.000172, val_loss=0.000260\n",
      "Epoch 14: train_loss=0.000173, val_loss=0.000294\n",
      "Epoch 15: train_loss=0.000168, val_loss=0.000310\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    #train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad() # limpiar gradientes anteriores\n",
    "        y_pred = model(X_batch) # forward: LSTM + fc\n",
    "        loss = criterion(y_pred, y_batch) # MSE entre preds y targets\n",
    "        loss.backward() # backprop: calcula gradientes\n",
    "        optimizer.step() # actualiza pesos del modelo\n",
    "        \n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    val_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: train_loss={train_loss:.6f}, val_loss={val_loss:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
